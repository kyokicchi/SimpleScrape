{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#General Crawler\n",
    "\n",
    "def SimpleSpider(orders,recipe,output):\n",
    "    import requests\n",
    "    import lxml.html\n",
    "    f = open(orders, 'r')\n",
    "    dump= f.read()\n",
    "    f.close()\n",
    "    l_url = dump.split('\\n')\n",
    "    l_out = []\n",
    "    for url in l_url:\n",
    "        if url != '':\n",
    "            response = requests.get(url)\n",
    "            html = lxml.html.fromstring(response.content)\n",
    "            l_res = []\n",
    "            l_res = html.xpath(recipe)\n",
    "            l_out.extend(l_res)\n",
    "\n",
    "    csv_out = \"\\n\".join(l_out)\n",
    "    f = open(output, 'w')\n",
    "    f.write(csv_out)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Execute Link collection crawling\n",
    "\n",
    "orders = 'target.txt'\n",
    "recipe = '//a[contains(@href, \"entry\") and (starts-with(@href,\"http://\") or starts-with(@href,\"https://\"))]/@href'\n",
    "output = 'results.csv'\n",
    "\n",
    "SimpleSpider(orders,recipe,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stations Page\n",
    "def parseStations(html):\n",
    "    title = html.xpath('//*[@class =\"entry-title\"]//a/text()')\n",
    "    title = title[0][:title[0].find('　')]\n",
    "    title = title.split('：')\n",
    "\n",
    "    h3 = html.xpath('//*[@class =\"entry-content\"]/h3')\n",
    "    h3_len =len(h3)\n",
    "    for i in range(h3_len):\n",
    "        h3_text = h3[i].xpath('text()')\n",
    "        h5 = h3[i].xpath('following-sibling::h5')\n",
    "        h5_len =len(h5)\n",
    "        if h5_len > 1:\n",
    "            for j in range(h5_len):\n",
    "                h5_text = h5[j].xpath('text()')\n",
    "                x = h5[j].xpath('following-sibling::p')\n",
    "                content = x[0].xpath('descendant::text()')\n",
    "                a = []\n",
    "                a.extend(title)\n",
    "                a.extend(h3_text)\n",
    "                a.extend(h5_text)\n",
    "                a.extend(content)\n",
    "                yield(a)\n",
    "        else:\n",
    "            x = h3[i].xpath('following-sibling::p')\n",
    "            content = x[0].xpath('descendant::text()')\n",
    "            a = []\n",
    "            a.extend(title)\n",
    "            a.extend(h3_text)\n",
    "            a.extend('-')\n",
    "            a.extend(content)\n",
    "            yield(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lines Page\n",
    "def parseLines(html):\n",
    "    title = html.xpath('//*[@class =\"entry-title\"]//a/text()')\n",
    "    title = title[0][:title[0].find('　')]\n",
    "    title = title.split('：')\n",
    "    title = title[0]\n",
    "    content = html.xpath('//*[@class =\"entry-content\"]//a/text()')\n",
    "    a = []\n",
    "    a.append(title)\n",
    "    a.extend(content)\n",
    "    yield(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html\n",
    "import pandas as pd\n",
    "\n",
    "res_lines = []\n",
    "res_stations = []\n",
    "\n",
    "f = open('order.txt', 'r')\n",
    "dump= f.read()\n",
    "f.close()\n",
    "l_url = dump.split('\\n')\n",
    "for url in l_url:\n",
    "    if url != \"\":\n",
    "        response = requests.get(url)\n",
    "        html = lxml.html.fromstring(response.content)\n",
    "        isStationPage = len(html.xpath('//*[@id =\"乗車停車位置案内\"]'))\n",
    "        if isStationPage ==1:\n",
    "            res_stations.extend(parseStations(html))\n",
    "        else:\n",
    "            res_lines.extend(parseLines(html))\n",
    "\n",
    "df_stations = pd.DataFrame(res_stations)\n",
    "df_stations = df_stations.drop_duplicates()\n",
    "df_stations.to_csv('stations.csv', header=None,index=None)\n",
    "\n",
    "df_lines = pd.DataFrame(res_lines)\n",
    "df_lines = df_lines.drop_duplicates()\n",
    "df_lines.to_csv('lines.csv', header=None,index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
